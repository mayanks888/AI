# import needed classes
from math import ceil

import keras
from keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, AveragePooling2D, Dropout, BatchNormalization, Activation
from keras.models import Model, Input
from keras.optimizers import Adam


def Unit(x, filters, pool=False):
    res = x
    if pool:
        x = MaxPooling2D(pool_size=(2, 2))(x)
        res = Conv2D(filters=filters, kernel_size=[1, 1], strides=(2, 2), padding="same")(res)
    out = BatchNormalization()(x)
    out = Activation("relu")(out)
    out = Conv2D(filters=filters, kernel_size=[3, 3], strides=[1, 1], padding="same")(out)

    out = BatchNormalization()(out)
    out = Activation("relu")(out)
    out = Conv2D(filters=filters, kernel_size=[3, 3], strides=[1, 1], padding="same")(out)

    out = keras.layers.add([res, out])

    return out


# Define the model


def MiniModel(input_shape):
    images = Input(input_shape)
    net = Conv2D(filters=32, kernel_size=[3, 3], strides=[1, 1], padding="same")(images)
    net = Unit(net, 32)
    net = Unit(net, 32)
    net = Unit(net, 32)

    net = Unit(net, 64, pool=True)
    net = Unit(net, 64)
    net = Unit(net, 64)

    net = Unit(net, 128, pool=True)
    net = Unit(net, 128)
    net = Unit(net, 128)

    net = Unit(net, 256, pool=True)
    net = Unit(net, 256)
    net = Unit(net, 256)

    net = BatchNormalization()(net)
    net = Activation("relu")(net)
    net = Dropout(0.25)(net)

    net = AveragePooling2D(pool_size=(4, 4))(net)
    net = Flatten()(net)
    net = Dense(units=10, activation="softmax")(net)

    model = Model(inputs=images, outputs=net)

    return model


# load the cifar10 dataset
'''(train_x, train_y) , (test_x, test_y) = cifar10.load_data()

#normalize the data
train_x = train_x.astype('float32') / 255
test_x = test_x.astype('float32') / 255

#Subtract the mean image from both train and test set
train_x = train_x - train_x.mean()
test_x = test_x - test_x.mean()

#Divide by the standard deviation
train_x = train_x / train_x.std(axis=0)
test_x = test_x / test_x.std(axis=0)


datagen = ImageDataGenerator(rotation_range=10,
                             width_shift_range=5. / 32,
                             height_shift_range=5. / 32,
                             horizontal_flip=True)

# Compute quantities required for featurewise normalization
# (std, mean, and principal components if ZCA whitening is applied).
datagen.fit(train_x)



#Encode the labels to vectors
train_y = keras.utils.to_categorical(train_y,10)
test_y = keras.utils.to_categorical(test_y,10)'''

# define a common unit


input_shape = (32, 32, 3)
model = MiniModel(input_shape)

# Print a Summary of the model

print(model.summary())
# Specify the training components
model.compile(optimizer=Adam(0.001), loss="categorical_crossentropy", metrics=["accuracy"])

epochs = 50
steps_per_epoch = ceil(50000 / 128)

# Fit the model on the batches generated by datagen.flow().
model.fit_generator(datagen.flow(train_x, train_y, batch_size=128),
                    validation_data=[test_x, test_y],
                    epochs=epochs, steps_per_epoch=steps_per_epoch, verbose=1, workers=4)

# Evaluate the accuracy of the test dataset
accuracy = model.evaluate(x=test_x, y=test_y, batch_size=128)
model.save("cifar10model.h5")
#
#
# import keras
#
#
# def Unit(x,filters,pool=False):
#     res = x
#     if pool:
#         x = MaxPooling2D(pool_size=(2, 2))(x)
#         res = Conv2D(filters=filters,kernel_size=[1,1],strides=(2,2),padding="same")(res)
#     out = BatchNormalization()(x)
#     out = Activation("relu")(out)
#     out = Conv2D(filters=filters, kernel_size=[3, 3], strides=[1, 1], padding="same")(out)
#
#     out = BatchNormalization()(out)
#     out = Activation("relu")(out)
#     out = Conv2D(filters=filters, kernel_size=[3, 3], strides=[1, 1], padding="same")(out)
#
#     out = keras.layers.add([res,out])
#
#     return out
#
# def Unit(x,filters,pool=False):
#     res = x
#     if pool:
#         x = MaxPooling2D(pool_size=(2, 2))(x)
#         res = Conv2D(filters=filters,kernel_size=[1,1],strides=(2,2),padding="same")(res)
#     out = BatchNormalization()(x)
#     out = Activation("relu")(out)
#     out = Conv2D(filters=filters, kernel_size=[3, 3], strides=[1, 1], padding="same")(out)
#
#     out = BatchNormalization()(out)
#     out = Activation("relu")(out)
#     out = Conv2D(filters=filters, kernel_size=[3, 3], strides=[1, 1], padding="same")(out)
#
#     out = keras.layers.add([res,out])
#
#     return out
#
# def MiniModel(input_shape):
#     images = Input(input_shape)
#     net = Conv2D(filters=32, kernel_size=[3, 3], strides=[1, 1], padding="same")(images)
#     net = Unit(net,32)
#     net = Unit(net,32)
#     net = Unit(net,32)
#
#     net = Unit(net,64,pool=True)
#     net = Unit(net,64)
#     net = Unit(net,64)
#
#     net = Unit(net,128,pool=True)
#     net = Unit(net,128)
#     net = Unit(net,128)
#
#     net = Unit(net, 256,pool=True)
#     net = Unit(net, 256)
#     net = Unit(net, 256)
#
#     net = BatchNormalization()(net)
#     net = Activation("relu")(net)
#     net = Dropout(0.25)(net)
#
#     net = AveragePooling2D(pool_size=(4,4))(net)
#     net = Flatten()(net)
#     net = Dense(units=10,activation="softmax")(net)
#
#     model = Model(inputs=images,outputs=net)
#
#     return model
